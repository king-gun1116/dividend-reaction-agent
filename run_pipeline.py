"""
run_pipeline.py (rev 2025-07-06g)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
End-to-End ë°°ë‹¹ ê³µì‹œ Agent íŒŒì´í”„ë¼ì¸
  â€¢ ì¦ë¶„ ìˆ˜ì§‘
  â€¢ æ—¥ ì¤‘ë³µ ê³µì‹œ í†µí•©(ìµœì‹  ì ‘ìˆ˜ë²ˆí˜¸ ê¸°ì¤€)
  â€¢ MLìš© ë°ì´í„° ì •ì œ (clean_ml_data í˜¸ì¶œ)
  â€¢ ì£¼ê°€ ìˆ˜ì§‘ & Â±10ê±°ë˜ì¼ ìœˆë„ìš° ê²€ì¦
  â€¢ ì„ë² ë”© & FAISS ìƒ‰ì¸
"""

from __future__ import annotations
import os
import pandas as pd
from dotenv import load_dotenv

# ë‚´ë¶€ ëª¨ë“ˆ
from utils.dart_api import collect_dividend_filings_incremental
from utils.data_cleaning import clean_ml_data
from utils.price_fetcher import run_price_fetching  # âœ… NEW
from utils import embed_utils


def run_pipeline(
    start_date: str = "20130101",
    end_date:   str = "20250630",
    data_dir:   str = "data",
    max_workers: int = 10,
) -> None:
    """ë°°ë‹¹ ê³µì‹œ Agent ì „ì²´ íŒŒì´í”„ë¼ì¸"""

    # 0ï¸. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv(dotenv_path=".env")
    os.makedirs(data_dir, exist_ok=True)

    # â”€â”€ ì£¼ìš” ê²½ë¡œ ì •ì˜
    csv_path      = os.path.join(data_dir, "dividend_with_text.csv")
    jsonl_path    = os.path.join(data_dir, "dividend_with_text.jsonl")
    ml_ready_path = os.path.join(data_dir, "dividend_ml_ready.csv")
    faiss_dir     = os.path.join(data_dir, "dividend_faiss_index")
    hist_path     = os.path.join(data_dir, "price_history.csv")
    check_path    = os.path.join(data_dir, "window_check_result.csv")
    cache_dir     = os.path.join(data_dir, "price_cache")

    # 1ï¸. ì¦ë¶„ ìˆ˜ì§‘
    print("\n 1. ë°°ë‹¹ê³µì‹œ ì¦ë¶„ ìˆ˜ì§‘ (ì´ë¯¸ ìˆ˜ì§‘ëœ ê±´ì€ ê±´ë„ˆëœ€)")
    new_records = collect_dividend_filings_incremental(
        start=start_date,
        end=end_date,
        save_csv=csv_path,
        save_jsonl=jsonl_path,
        existing_jsonl=jsonl_path,
        max_workers=max_workers,
    )
    print(f"â–¶ ì‹ ê·œ ìˆ˜ì§‘ ê±´ìˆ˜: {len(new_records):,}ê±´")

    # 2ï¸. MLìš© ë°ì´í„° ì •ì œ
    print("\n 2. MLìš© ë°ì´í„° ì¤€ë¹„ ë° ì •ì œ")
    df = pd.read_csv(csv_path, encoding="utf-8-sig")
    print(f"ì›ë³¸ shape: {df.shape}")
    df = clean_ml_data(df)
    print(f"ì •ì œ í›„ shape: {df.shape}")
    df.to_csv(ml_ready_path, index=False, encoding="utf-8-sig")
    print(f"âœ… MLìš© ë°ì´í„° ì €ì¥ â†’ {ml_ready_path}")

    # 2.1 ì£¼ê°€ ìˆ˜ì§‘ & ìœˆë„ìš° ê²€ì¦
    print("\n 2.1 ì£¼ê°€ ìˆ˜ì§‘ & ìœˆë„ìš° ê²€ì¦")
    run_price_fetching(
        div_path=ml_ready_path,
        hist_path=hist_path,
        check_path=check_path,
        cache_dir_path=cache_dir,
        window_days=30,
        max_workers=max_workers,
    )

    # 3ï¸. ì„ë² ë”© & FAISS ì¸ë±ì‹±
    print("\n 3. Agent ìƒ‰ì¸ (ì„ë² ë”© ë° FAISS ì¸ë±ì‹±)")
    embed_utils.jsonl_to_faiss(
        jsonl_path=jsonl_path,
        faiss_path=faiss_dir,
    )
    print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ â†’ {faiss_dir}")

    print("\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")


if __name__ == "__main__":
    run_pipeline()
